                                         People use AI more than you think - by Nathan Lambert                     

[

![Interconnects](https://substackcdn.com/image/fetch/w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)



](/)

# [![Interconnects](https://substackcdn.com/image/fetch/e_trim:10:white/e_trim:10:transparent/h_72,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d81586c-6633-4f53-917d-dac1b61613d9_3009x724.png)](/)

SubscribeSign in

#### Share this post

[

![](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8dd789-eb58-445d-85dc-b49617bc781d_1671x956.jpeg)

![Interconnects](https://substackcdn.com/image/fetch/w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)

Interconnects

People use AI more than you think







](https://substack.com/home/post/p-163721927?utm_campaign=post&utm_medium=web)

Copy link

Facebook

Email

Notes

More

# People use AI more than you think

### And businesses too. The most important trend in AI that gets washed away from between the headlines.

[Nathan Lambert](https://substack.com/@natolambert)

May 21, 2025

21

#### Share this post

[

![](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8dd789-eb58-445d-85dc-b49617bc781d_1671x956.jpeg)

![Interconnects](https://substackcdn.com/image/fetch/w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)

Interconnects

People use AI more than you think







](https://substack.com/home/post/p-163721927?utm_campaign=post&utm_medium=web)

Copy link

Facebook

Email

Notes

More

[

1

](https://www.interconnects.ai/p/people-use-ai-more-than-you-think/comments)

3

[

Share

](javascript:void\(0\))

Article voiceover

1Ã—

0:00

\-8:46

Audio playback is not supported on your browser. Please upgrade.

*I was [on ChinaTalk again](https://open.spotify.com/episode/5yPJwQkzhRPuEsLHuZTq1o) recently to talk through some of my recent pieces and their corresponding happenings in AI.*

* * *

Usage and revenue growth for most AI services, especially inference APIs, has been growing like mad for a long time.[1](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-1-163721927) These APIs have been very profitable for companies â€” up to 75% or higher margins at times [according to Dylan Patel of SemiAnalysis](https://lexfridman.com/deepseek-dylan-patel-nathan-lambert-transcript/). This is one of those open facts that has been known among the people building AI that can be lost to the broader public in the chorus of new releases and capabilities excitement.

I expect the subscription services are profitable too on the average user, but power users likely are costs to the AI companies alongside the obvious capital expenditures of training frontier models. Still, even if the models were held constant, the usage is growing exponentially and a lot of it is in the realm of profitability.

The extreme, and in some cases exponential, growth in use of AI has been happening well before lots of the incredible progress weâ€™ve seen across the industry in the first half of the year. Reasoning models that change inference answers from something on the order of 100s of tokens to sometimes 10s of thousands of tokens will make the plots of usage even more stark. At the same time, these models are often billed per token so thatâ€™ll all result in more revenue.

[Share](https://www.interconnects.ai/p/people-use-ai-more-than-you-think?utm_source=substack&utm_medium=email&utm_content=share&action=share)

On top of the industryâ€™s vast excitement and progress in 2025, the Google I/O keynote yesterday was a great â€œState of the Unionâ€ for AI that highlighted this across modalities, form factors, and tasks. It is really [recommended viewing](https://www.youtube.com/watch?v=o8NiE3XMPrM). Google is trying to compete on every front. Theyâ€™re positioned to win a couple use-cases and be in the top 3 of the rest. No other AI company is close to this â€” weâ€™ll see how their product culture can adapt.

Highlights from I/O include Googleâ€™s equivalent product relative to OpenAIâ€™s o1 Pro, Gemini Deep Think, Googleâ€™s new multimodal models such as Veo 3 *with audio* (a first to my knowledge for the major players), a *live* demo of an augmented reality headset to rival Meta and Apple, and a new version of Gemini 2.5 Flash thatâ€™ll serve as the foundation of most customersâ€™ interactions with Gemini.

There were so many awesome examples in the keynote that they didnâ€™t really make sense writing about on their own. Theyâ€™re paths weâ€™ve seen laid out in front of us for a while, but Google and co are marching down them faster than most people expected. Most of the frontier language modeling evaluations are totally saturated. This is why the meta usage data that Google (and others recently) have shared is the right focal point. Itâ€™s not about one model, itâ€™s about the movement being real.

The slide that best captured this was this one of AI tokens processed[2](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-2-163721927) across all of Googleâ€™s AI surfaces (i.e. this includes all modalities), and it is skyrocketing in the last few months.

[

![Image](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8dd789-eb58-445d-85dc-b49617bc781d_1671x956.jpeg "Image")



](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8dd789-eb58-445d-85dc-b49617bc781d_1671x956.jpeg)

Timestamp is [here](https://www.youtube.com/live/o8NiE3XMPrM?si=SJsga6osWbD_bJF6&t=394)

I annotated the plot to approximate that the inflection point in February was at about 160T total tokens in a month â€” [Gemini 2.5 Proâ€™s release](https://www.interconnects.ai/p/gemini-25-pro-googles-second-ai-chance) was in late March, which surely contributed but was not the only cause of the inflection point. Roughly, the numbers are as follows:

*   April 2024: 9.7T tokens
    
*   December 2024: 90T tokens
    
*   February 2025: 160T tokens
    
*   March 2025: 300T tokens
    
*   April 2025: 480T+ tokens
    

Monthly tokens are rapidly approaching 1 quadrillion. Not all tokens are created equal, but this is about 150-200M tokens per second. In a world with [5T Google searches annually](https://blog.google/products/ads-commerce/ai-personalization-and-the-future-of-shopping/), which translates to around 100K searches/second, that tokens per second number is equivalent to roughly using 1000 tokens per search (even though that is definitely not how compute is allocated). These are mind boggling numbers of tokens.[3](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-3-163721927)

Googleâ€™s primary AI product is still its search overviews built on Gemini models and theyâ€™ve been saying again and again that theyâ€™re something users love, [reaching more than a billion people](https://blog.google/technology/ai/io-2025-keynote/) (we just donâ€™t know how they are served, as I suspect the same generation is used for thousands of users).

Interconnects is a reader-supported publication. Consider becoming a subscriber.

Subscribe

Google is generating more tokens than is stored in [Common Crawl](https://commoncrawl.org/) every month â€” reminder, Common Crawl is the standard that would be referred to as a â€œsnapshot of the open webâ€ or the starting point for AI pretraining datasets. One effort to use Common Crawl for pretraining, the [RedPajama 2](https://www.together.ai/blog/redpajama-data-v2#:~:text=and%20deduplicated%20tokens%20\(-,100%2B%20trillions%20raw,-\)%20from%2084%20CommonCrawl) work from Together AI, estimated the raw data in Common Crawl at about 100T tokens, of which anywhere from 5 to 30T tokens are often used for pretraining. In a year or two, it is conceivable that Google will be processing that many tokens in a day.

[This article](https://www.educatingsilicon.com/2024/05/09/how-much-llm-training-data-is-there-in-the-limit/) has some nice estimates on how different corners of the internet compare to dumps like Common Crawl or generations like those from Googleâ€™s Gemini. It puts the daily token processing of Google as a mix of reading or generating all the data in Google Books in four hours or *all the instant messages stored in the world* in a little over a month.

Some examples from the post are below:

[

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f124db-90f0-42a3-93ce-8e319df5dd00_1074x972.png)



](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f124db-90f0-42a3-93ce-8e319df5dd00_1074x972.png)

The internet is being rebuilt as an AI first service when you count the data. Human data will quickly become obsolete.

Googleâ€™s numbers are impressive, but they are far from outliers. The entire industry is taking off. This is all part of a constant acceleration where products that are built on previous models start to get traction, while at the same time new models come out that only enable new growth cycles to begin. Estimating the upper end of this growth cycle feels near impossible.

For example, just a few weeks ago on the [Q3 2025 earnings](https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q3), Microsoft CEO Satya Nadella commented on the output of Azureâ€™s AI services:

> We processed over 100 trillion tokens this quarter, up 5Ã— year-over-year â€” including a record 50 trillion tokens last month alone.

So, Googleâ€™s token processing is almost 10X Azure, and many would say that Google got a late start relative to Microsoftâ€™s early partnership with OpenAI to host their models.

Estimates for other services, such as ChatGPT are much messier (private company & outdated information), but all paint a similar picture. Sam Altman [posted on X](https://x.com/sama/status/1756089361609981993?utm_source=chatgpt.com) in Feb. of 2024:

> openai now generates about 100 billion words per day.  
> all people on earth generate about 100 trillion words per day.

With the rule of thumb that one word is about 3/4 of a token, 100B words per day would be about 4T tokens per month. This would be about 1/2 of Googleâ€™s number from April of 2024, which is somewhere between interesting and impressive.

We need more information to know if OpenAIâ€™s growth has mirrored Googleâ€™s closely, but a lot of basic context on ChatGPTâ€™s evolution point to it doing so in general. Trends across ChatGPT have been more users, more messages per user, and more tokens generated per message. Iâ€™d estimate that ChatGPTâ€™s token processing numbers are bigger than Azure and smaller than Google.

The multi-model API [OpenRouterâ€™s rankings show similar trends](https://openrouter.ai/rankings), with the recent months being around 2T tokens processed â€” about the same order of magnitude as ChatGPT from a year ago depending on how it is measured above.[4](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-4-163721927)

[

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa30cffbe-1f86-4eef-90fe-cda1db859d32_2094x1018.png)



](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa30cffbe-1f86-4eef-90fe-cda1db859d32_2094x1018.png)

This isnâ€™t just Western businesses, as Chinese companies such as ByteDance or Baidu [are getting into the 1T token](https://www.lesswrong.com/posts/4x4QFzmdWadgr7mdj/translation-in-the-age-of-ai-don-t-look-for-unicorns) *[per day](https://www.lesswrong.com/posts/4x4QFzmdWadgr7mdj/translation-in-the-age-of-ai-don-t-look-for-unicorns)* [range](https://www.lesswrong.com/posts/4x4QFzmdWadgr7mdj/translation-in-the-age-of-ai-don-t-look-for-unicorns) (barring translation issues, I didnâ€™t find another source for it).

When fast-growing companies like Anthropic or OpenAI share somewhat [unbelievable](https://www.reuters.com/technology/artificial-intelligence/openai-does-not-expect-be-cash-flow-positive-until-2029-bloomberg-news-reports-2025-03-26/?utm_source=chatgpt.com) [revenue forecasts](https://www.bloomberg.com/news/features/2025-05-19/anthropic-ceo-amodei-steers-61-billion-ai-powerhouse?utm_source=chatgpt.com), maybe we should give them a bit more credit?

There are many surfaces that are in beta, primarily code agents, that are going to help these numbers take off. Weâ€™ve been playing with Claude Code, OpenAIâ€™s Codex, Googleâ€™s Jules, and countless other agents that use tons of text tokens by working independently for minutes at a time. Iâ€™ve estimated with friends that one Deep Research query uses ~1M tokens of inference. Soon individual tasks will use ~10M then ~100M and so on.[5](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-5-163721927) All of this so soon after just two years ago when a mind-blowing ChatGPT query only used 100-1K tokens.

Itâ€™s a good time to be in the token selling business. This is only the beginning.

[1](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-anchor-1-163721927)

For example, we discussed this somewhere on my Lex Fridman appearance:

[2](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-anchor-2-163721927)

This includes input, output, and whatever tokens at Googleâ€™s whim.

[

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4ef19f9-4530-40a5-a7f2-4e79c14e929d_1671x956.jpeg)



](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4ef19f9-4530-40a5-a7f2-4e79c14e929d_1671x956.jpeg)

[3](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-anchor-3-163721927)

Inspiration for this a bit: https://x.com/ptrschmdtnlsn/status/1924984659315982580

[4](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-anchor-4-163721927)

Of course, you need to control for how individual businesses relative adoption goes, but that is too hard to do with the data we have.

[5](https://www.interconnects.ai/p/people-use-ai-more-than-you-think#footnote-anchor-5-163721927)

Not without downsides, e.g. that Veo 3 with audio is going very viral and likely to make its way to the short term video feeds as mega addicting content (examples [here](https://x.com/fofrai/status/1924924738494669011) and [here](https://x.com/jen_w1n/status/1924914469265649795)).

* * *

#### Subscribe to Interconnects

Hundreds of paid subscribers

The cutting edge of AI, from inside the frontier AI labs, minus the hype. The border between high-level and technical thinking. Read by leading engineers, researchers, and investors on Wednesday mornings.

Subscribe

By subscribing, I agree to Substack's [Terms of Use](https://substack.com/tos), and acknowledge its [Information Collection Notice](https://substack.com/ccpa#personal-data-collected) and [Privacy Policy](https://substack.com/privacy).

[

![Joseph Grillo's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f144a1c-69c6-4782-8a4a-dcf887d67c33_1166x1168.jpeg)



](https://substack.com/profile/13139062-joseph-grillo)

[

![James Bernard Moore's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77c82b6d-08de-48b9-84d7-4e29652c7cf5_256x336.png)



](https://substack.com/profile/64546-james-bernard-moore)

[

![Jax's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7f9e8dd-ef5d-46da-b4ce-289cb652760e_1016x1016.jpeg)



](https://substack.com/profile/161363912-jax)

[

![Andrei Villarroel, PhD's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed9fc0d3-ee3c-4552-b174-27d173bfe243_1115x1115.jpeg)



](https://substack.com/profile/140318020-andrei-villarroel-phd)

[

![Lorenzo Bradanini's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18342bf1-31cb-404a-b9e1-998a38d299bf_1200x1200.jpeg)



](https://substack.com/profile/201922174-lorenzo-bradanini)

21 Likesâˆ™

[3 Restacks](https://substack.com/note/p-163721927/restacks?utm_source=substack&utm_content=facepile-restacks)

21

#### Share this post

[

![](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8dd789-eb58-445d-85dc-b49617bc781d_1671x956.jpeg)

![Interconnects](https://substackcdn.com/image/fetch/w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)

Interconnects

People use AI more than you think







](https://substack.com/home/post/p-163721927?utm_campaign=post&utm_medium=web)

Copy link

Facebook

Email

Notes

More

[

1

](https://www.interconnects.ai/p/people-use-ai-more-than-you-think/comments)

3

[

Share

](javascript:void\(0\))

Previous

#### Discussion about this post

CommentsRestacks

![User's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png)

[

![James Wang's avatar](https://substackcdn.com/image/fetch/w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7ea988e-c6f5-4b1e-9041-8a3081bccb3f_2200x2220.jpeg)



](https://substack.com/profile/7343257-james-wang?utm_source=comment)

[James Wang](https://substack.com/profile/7343257-james-wang?utm_source=substack-feed-item)

[1h](https://www.interconnects.ai/p/people-use-ai-more-than-you-think/comment/119030972 "May 21, 2025, 11:03 AM")

It's definitely been the case of "more AI than you think" for a while now! There was a McKinsey report from earlier this year that C-suite leaders thought 4% of employees used it for a substantial (30%+) amount of work... but 12% actually do.

Also, 94% of employees and 99% of C-suite knew about AI. Everything that can heavily utilize AI will do so (especially with falling costs)â€”and probably should, in terms of the kinds of work it typically replaces.

Expand full comment

[

Like



](javascript:void\(0\))

Reply

Share

TopLatestDiscussions

[The Q\* hypothesis: Tree-of-thoughts reasoning, process reward models, and supercharging synthetic data](https://www.interconnects.ai/p/q-star)

[Emergency special: The information we need to understand what Q\* is was right in front of us, but the memes are more fun than reality.](https://www.interconnects.ai/p/q-star)

Nov 24, 2023Â â€¢Â 

[Nathan Lambert](https://substack.com/@natolambert)

102

#### Share this post

[

![](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg)

![Interconnects](https://substackcdn.com/image/fetch/w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)

Interconnects

The Q\* hypothesis: Tree-of-thoughts reasoning, process reward models, and supercharging synthetic data







](https://substack.com/home/post/p-139117155?utm_campaign=post&utm_medium=web)

Copy link

Facebook

Email

Notes

More

[

5

](https://www.interconnects.ai/p/q-star/comments)

[](javascript:void\(0\))

![](https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg)

[Behind the curtain: what it feels like to work in AI right now (April 2023)](https://www.interconnects.ai/p/behind-the-curtain-ai)

[Fear, FOMO, and the scientific exodus driven by ChatGPT](https://www.interconnects.ai/p/behind-the-curtain-ai)

Apr 5, 2023Â â€¢Â 

[Nathan Lambert](https://substack.com/@natolambert)

97

#### Share this post

[

![](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg)

![Interconnects](https://substackcdn.com/image/fetch/w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)

Interconnects

Behind the curtain: what it feels like to work in AI right now (April 2023)







](https://substack.com/home/post/p-112453991?utm_campaign=post&utm_medium=web)

Copy link

Facebook

Email

Notes

More

[

21

](https://www.interconnects.ai/p/behind-the-curtain-ai/comments)

[](javascript:void\(0\))

![](https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg)

[DeepSeek R1's recipe to replicate o1 and the future of reasoning LMs](https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1)

[Yes, ring the true o1 replication bells for DeepSeek R1 ðŸ””ðŸ””ðŸ””. Where we go next.](https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1)

Jan 21Â â€¢Â 

[Nathan Lambert](https://substack.com/@natolambert)

230

#### Share this post

[

![](https://substackcdn.com/image/fetch/w_520,h_272,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f93598d-e3e4-4f7f-8452-c4d5f1501e94_1280x720.png)

![Interconnects](https://substackcdn.com/image/fetch/w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png)

Interconnects

DeepSeek R1's recipe to replicate o1 and the future of reasoning LMs







](https://substack.com/home/post/p-155269286?utm_campaign=post&utm_medium=web)

Copy link

Facebook

Email

Notes

More

[

2

](https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1/comments)

[](javascript:void\(0\))

![](https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f93598d-e3e4-4f7f-8452-c4d5f1501e94_1280x720.png)

See all

Ready for more?

Subscribe

Â© 2025 Interconnects AI, LLC

[Privacy](https://substack.com/privacy) âˆ™ [Terms](https://substack.com/tos) âˆ™ [Collection notice](https://substack.com/ccpa#personal-data-collected)

[Start writing](https://substack.com/signup?utm_source=substack&utm_medium=web&utm_content=footer)[Get the app](https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&utm_content=web-footer-button)

[Substack](https://substack.com) is the home for great culture

#### Share

[

](https://www.interconnects.ai/p/people-use-ai-more-than-you-think?utm_campaign=unknown&utm_medium=web)

Copy link

Facebook

Email

Notes

More

#### Create your profile

![User's avatar](https://substackcdn.com/image/fetch/w_94,h_94,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png)

Name\*

Email\*

Handle

Bio

Subscribe to the newsletter

I agree to Substack's [Terms of Use](https://substack.com/tos), and acknowledge its [Information Collection Notice](https://substack.com/ccpa#personal-data-collected) and [Privacy Policy](https://substack.com/privacy).

Save & Post Comment

## Only paid subscribers can comment on this post

[Subscribe](https://www.interconnects.ai/subscribe?simple=true&next=https%3A%2F%2Fwww.interconnects.ai%2Fp%2Fpeople-use-ai-more-than-you-think&utm_source=paywall&utm_medium=web&utm_content=163721927)

[Already a paid subscriber? **Sign in**](https://substack.com/sign-in?redirect=%2Fp%2Fpeople-use-ai-more-than-you-think&for_pub=robotic&change_user=false)

#### Check your email

For your security, we need to re-authenticate you.

Click the link we sent to , or [click here to sign in](https://substack.com/sign-in?redirect=%2Fp%2Fpeople-use-ai-more-than-you-think&for_pub=robotic&with_password=true).